@inproceedings{xu2015show,
  title={Show, attend and tell: Neural image caption generation with visual attention},
  author={Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhudinov, Ruslan and Zemel, Rich and Bengio, Yoshua},
  booktitle={International conference on machine learning},
  pages={2048--2057},
  year={2015},
  organization={PMLR}
}

@inproceedings{cornia2020meshed,
  title={Meshed-memory transformer for image captioning},
  author={Cornia, Marcella and Stefanini, Matteo and Baraldi, Lorenzo and Cucchiara, Rita},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10578--10587},
  year={2020}
}

@article{hossain2019comprehensive,
  title={A comprehensive survey of deep learning for image captioning},
  author={Hossain, MD Zakir and Sohel, Ferdous and Shiratuddin, Mohd Fairuz and Laga, Hamid},
  journal={ACM Computing Surveys (CsUR)},
  volume={51},
  number={6},
  pages={1--36},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@article{stefanini2022show,
  title={From show to tell: a survey on deep learning-based image captioning},
  author={Stefanini, Matteo and Cornia, Marcella and Baraldi, Lorenzo and Cascianelli, Silvia and Fiameni, Giuseppe and Cucchiara, Rita},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2022},
  publisher={IEEE}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{sutton1999policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
  journal={Advances in neural information processing systems},
  volume={12},
  year={1999}
}

@inproceedings{cho2021unifying,
  title={Unifying vision-and-language tasks via text generation},
  author={Cho, Jaemin and Lei, Jie and Tan, Hao and Bansal, Mohit},
  booktitle={International Conference on Machine Learning},
  pages={1931--1942},
  year={2021},
  organization={PMLR}
}

@article{tan2019lxmert,
  title={Lxmert: Learning cross-modality encoder representations from transformers},
  author={Tan, Hao and Bansal, Mohit},
  journal={arXiv preprint arXiv:1908.07490},
  year={2019}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{zhang2021vinvl,
  title={Vinvl: Revisiting visual representations in vision-language models},
  author={Zhang, Pengchuan and Li, Xiujun and Hu, Xiaowei and Yang, Jianwei and Zhang, Lei and Wang, Lijuan and Choi, Yejin and Gao, Jianfeng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5579--5588},
  year={2021}
}

@inproceedings{li2020oscar,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
  booktitle={European Conference on Computer Vision},
  pages={121--137},
  year={2020},
  organization={Springer}
}

@inproceedings{desai2021virtex,
  title={Virtex: Learning visual representations from textual annotations},
  author={Desai, Karan and Johnson, Justin},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11162--11173},
  year={2021}
}

@article{mokady2021clipcap,
  title={Clipcap: Clip prefix for image captioning},
  author={Mokady, Ron and Hertz, Amir and Bermano, Amit H},
  journal={arXiv preprint arXiv:2111.09734},
  year={2021}
}

@article{touvron2021resmlp,
  title={Resmlp: Feedforward networks for image classification with data-efficient training},
  author={Touvron, Hugo and Bojanowski, Piotr and Caron, Mathilde and Cord, Matthieu and El-Nouby, Alaaeldin and Grave, Edouard and Izacard, Gautier and Joulin, Armand and Synnaeve, Gabriel and Verbeek, Jakob and others},
  journal={arXiv preprint arXiv:2105.03404},
  year={2021}
}


@inproceedings{luong2015stanford,
  title={Stanford neural machine translation systems for spoken language domains},
  author={Luong, Minh-Thang and Manning, Christopher D},
  booktitle={Proceedings of the 12th International Workshop on Spoken Language Translation: Evaluation Campaign},
  year={2015}
}

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}

@article{luong2015effective,
  title={Effective approaches to attention-based neural machine translation},
  author={Luong, Minh-Thang and Pham, Hieu and Manning, Christopher D},
  journal={arXiv preprint arXiv:1508.04025},
  year={2015}
}

@inproceedings{yang2018graph,
  title={Graph r-cnn for scene graph generation},
  author={Yang, Jianwei and Lu, Jiasen and Lee, Stefan and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={670--685},
  year={2018}
}

@article{meng2016interactive,
  title={Interactive attention for neural machine translation},
  author={Meng, Fandong and Lu, Zhengdong and Li, Hang and Liu, Qun},
  journal={arXiv preprint arXiv:1610.05011},
  year={2016}
}

@article{jean2014using,
  title={On using very large target vocabulary for neural machine translation},
  author={Jean, S{\'e}bastien and Cho, Kyunghyun and Memisevic, Roland and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.2007},
  year={2014}
}

@article{luong2014addressing,
  title={Addressing the rare word problem in neural machine translation},
  author={Luong, Minh-Thang and Sutskever, Ilya and Le, Quoc V and Vinyals, Oriol and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1410.8206},
  year={2014}
}

@article{tang2016neural,
  title={Neural machine translation with external phrase memory},
  author={Tang, Yaohua and Meng, Fandong and Lu, Zhengdong and Li, Hang and Yu, Philip LH},
  journal={arXiv preprint arXiv:1606.01792},
  year={2016}
}

@article{wang2016memory,
  title={Memory-enhanced decoder for neural machine translation},
  author={Wang, Mingxuan and Lu, Zhengdong and Li, Hang and Liu, Qun},
  journal={arXiv preprint arXiv:1606.02003},
  year={2016}
}

@article{zhou2016deep,
  title={Deep recurrent models with fast-forward connections for neural machine translation},
  author={Zhou, Jie and Cao, Ying and Wang, Xuguang and Li, Peng and Xu, Wei},
  journal={Transactions of the Association for Computational Linguistics},
  volume={4},
  pages={371--383},
  year={2016},
  publisher={MIT Press}
}

@inproceedings{li2016towards,
  title={Towards Zero Unknown Word in Neural Machine Translation.},
  author={Li, Xiaoqing and Zhang, Jiajun and Zong, Chengqing},
  booktitle={IJCAI},
  pages={2852--2858},
  year={2016}
}

@article{tu2016modeling,
  title={Modeling coverage for neural machine translation},
  author={Tu, Zhaopeng and Lu, Zhengdong and Liu, Yang and Liu, Xiaohua and Li, Hang},
  journal={arXiv preprint arXiv:1601.04811},
  year={2016}
}

@article{shen2015minimum,
  title={Minimum risk training for neural machine translation},
  author={Shen, Shiqi and Cheng, Yong and He, Zhongjun and He, Wei and Wu, Hua and Sun, Maosong and Liu, Yang},
  journal={arXiv preprint arXiv:1512.02433},
  year={2015}
}

@article{feng2016implicit,
  title={Implicit distortion and fertility models for attention-based encoder-decoder NMT model},
  author={Feng, Shi and Liu, Shujie and Li, Mu and Zhou, Ming},
  journal={arXiv preprint arXiv:1601.03317},
  year={2016}
}

@article{schuster1997bidirectional,
  title={Bidirectional recurrent neural networks},
  author={Schuster, Mike and Paliwal, Kuldip K},
  journal={IEEE transactions on Signal Processing},
  volume={45},
  number={11},
  pages={2673--2681},
  year={1997},
  publisher={Ieee}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{graves2014neural,
  title={Neural turing machines},
  author={Graves, Alex and Wayne, Greg and Danihelka, Ivo},
  journal={arXiv preprint arXiv:1410.5401},
  year={2014}
}